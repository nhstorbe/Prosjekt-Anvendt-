
# 游깴 Mappe 1: Datainnsamling og forberedelse
I den f칮rste mappen i prosjektet var form친let 친 sette opp et utviklingsmilj칮, samle inn data og behandle og analysere den. 

![Bilde](/resources/Bilde2.webp)
Bildet er hentet fra ([AlphaTarget](https://alphatarget.com/resources/a-primer-on-artificial-intelligence/), 2024)



#
### Innhold 
Gruppen har valgt 친 dele alle oppgavene i to deler, da analysen gjennomf칮res med to ulike datasett: historiske data og fremtidsrettet data. Begge datasettene er hentet fra Yr.no og analyseres separat. Oppgavene og implementeringen er dokumentert i f칮lgende filer: 

Besvarelse for oppgave 1:
- [Testing av utviklingsmilj칮](/src/mappe1/utviklingsmilj칮.ipynb)

Besvarelse for oppgave 2 og oppgave 3:
- [Databehandling av historisk data](/src/mappe1/data_behandling_historisk.ipynb)
- [Databehandling av fremtidsrettet data](/src/mappe1/data_behandling_fremtid.ipynb)

Overf칮ring til python for testing:
- [Databehandling av historisk data](/src/mappe1/API_historisk.py)
- [Databehandling av fremtidsrettet data](/src/mappe1/API_fremtid.py)

Tilh칮rende test filer:
- [Test for historisk data](/tests/test_APIhistorisk.py)
- [Test for fremtidig data](/tests/test_APIfremtid.py)

Tilh칮rende CSV-filer:
- [V칝rdata i csv format](/data/weather_data.csv)




#
### Oppgave 2 - Datainnsamling

[Url til git repository:](https://github.com/nhstorbe/Prosjekt-Anvendt-)

1) P친 internett finnes det en stor mengde brukbare kilder p친 relevant data for v칝rmeldinger. Gruppen har valgt 친 bruke v칝rdata fra [Yr.no](https://hjelp.yr.no/hc/no/articles/206550539-Om-Yr) for 친 l칮se alle oppgavene i prosjektet. Yr.no drives i samarbeid mellom NRK og Meteorologisk institutt, og anses som en p친litelig datakilde ettersom begge akt칮rene er statlige institusjoner. 

2) For valg av dataformat, gav Yr.no mulighet for 친 velge mellom ulike formater for nedlastning av data. Det var mulig 친 brke blant annet JSON-filer, CSV-filer og XML-filer.For den historiske dataen ble CSV-filer benyttet, ettersom dette formatet var lett tilgjengelig fra Yr og enkelt 친 integrere med Pandas.
For fremtidsrettet data ble Yr sitt API benyttet. Dataen ble hentet i JSON-format da dette formatet er strukturert og enkelt 친 anvende i Python. I tillegg var gruppen kjent med dictonery fra tidligere kurs. 

3) APIen, i fremtidsrettet data, henter ned en JSON-fil p친 spesifiserte lengde- og breddegrader (som kan endres i en link) fra meterologisk institutt sin nettside. Den tillater oss 친 kj칮re programmet med oppdatert forecasts data hver gang programmet kj칮res for spesifike steder, noe som gir enorm fleksibilitet. De ble hentet ned dato-tidsgruppe, temperatur, nedb칮rsmengde og vindhastighet fra dataen. 

4) Om Funkjsonene:
- visualiser_data: henter informasjon om v칝rstasjoner fra Frost API ved hjelp av brukerens klient-ID. Den sender en foresp칮rsel til API-et for 친 f친 en oversikt over alle tilgjengelige stasjoner. Deretter filtrerer den ut og strukturerer relevante data, som stasjons-ID, navn og land, og konverterer dette til en pandas DataFrame. Til slutt filtreres kun de stasjonene som ligger i Norge, slik at vi f친r en oversikt over norske v칝rstasjoner som kan brukes videre i datainnsamling eller analyse. Funksjonen returnerer en tabell (DataFrame) med informasjon om disse norske stasjonene.
- get_station_id_by_name: tar en klient-ID og et s칮kebegrep som input for 친 finne en v칝rstasjon basert p친 navnet. Den henter f칮rst en liste over alle tilgjengelige stasjoner i Norge ved hjelp av funksjonen visualiserer_data. Deretter s칮ker den etter stasjoner som har et navn som inneholder s칮kebegrepet, uavhengig av store og sm친 bokstaver. Hvis 칠n matchende stasjon finnes, returneres dens ID. Hvis flere stasjoner matcher, vises en liste med disse stasjonene, og den f칮rste stasjonen velges som standard. Hvis ingen stasjoner matcher, f친r brukeren beskjed om at ingen resultater ble funnet.
- fetch_hourly_weather_to_csv brukes til 친 hente timesoppl칮ste v칝rdata fra Meteorologisk institutts Frost API, basert p친 en spesifikk stasjon, dato-intervall og 칮nskede v칝rparametere. Den henter data for lufttemperatur, relativ luftfuktighet, middelvind og nedb칮r, og lagrer resultatene i en CSV-fil. For hver av de valgte v칝rparametrene defineres passende elementkoder som benyttes i foresp칮rslene til API-et. Dataene behandles og struktureres i en felles datastruktur f칮r de lagres i fil.
I fors칮ket p친 친 hente timesbaserte nedb칮rsdata fra Frost API fikk vi en "412 Precondition Failed"-feil. Dette tror vi skyldes at Meteorologisk institutt ikke benytter seg av en timeoppl칮sning for nedb칮r p친 den valgte stasjonen. Vi testet med flere stasjoner og fikk fortsatt ikke tak i nedb칮rsdata i timesoppl칮sning, og antar derfor at Meteorologisk institutt kun leverer nedb칮r p친 d칮gnbasis. I tillegg m친 man bruke sum n친r man henter ut nedb칮rsdata, da nedb칮r registreres som en akkumulert verdi over tid. For de 칮vrige variablene som lufttemperatur, relativ luftfuktighet og middelvind benyttes derimot mean, ettersom disse verdiene representerer gjennomsnitt i l칮pet av en gitt time. Det er likevel verdt 친 merke seg at kolonnen for nedb칮r fortsatt eksisterer i CSV-filen, men den inneholder ingen verdier. Dette gir fleksibilitet for fremtidig utfylling dersom nedb칮rsdata i 칮nsket oppl칮sning skulle bli tilgjengelig.

For 친 forst친 dataens struktur og innhold har vi benyttet oss av diverse funksjoner 
- Vi startet med 친 bruke list comprehensions for 친 trekke ut spesifikke verdier, som for eksempel temperaturene, direkte fra DataFrame-en p친 en effektiv m친te. Et eksempel p친 dette er funksjonen hent_varme_dager, som returnerer en liste over tidspunkt og temperatur for alle observasjoner der temperaturen overstiger en gitt grense.
- Deretter tok vi i bruk en iterator med df.iterrows() for 친 bla gjennom DataFrame-radene 칠n etter 칠n. Dette gj칮r det mulig 친 hente ut og presentere flere kolonneverdier samtidig p친 en oversiktlig m친te. Vi laget en funksjon vis_observasjoner, som skriver ut stasjonsnavn, tidspunkt og relativ fuktighet for de f칮rste observasjonene i datasettet.
- Til slutt benyttet vi pandasql for 친 filtrere og analysere datasettet ved hjelp av SQL-syntaks direkte p친 DataFrame-en. Dette gj칮r det enklere 친 trekke ut spesifikke verdier basert p친 betingelser, som for eksempel alle tilfeller der middelvinden overstiger 10 m/s. Vi laget funksjonen hent_vind_over_grense for 친 gj칮re dette p친 en fin m친te.
 
#
### Oppgave 3 - Databehandling
1) For 친 h친ndtere manglende verdier i datasettet, benyttet vi flere metoder. I b친de ["Historisk databehnadling](/src/Mappe%201/data_behandling_historisk.ipynb) og ["Fremtidig databehandling"](/src/Mappe%201/data_behandling_fremtid.ipynb) startet vi med 친 unders칮ke om det fantes hull i dataene. Til dette brukte vi funksjoner som _check_NaN_counter(place)_ og _print(df.isnull().sum())_ for 친 identifisere antall manglende verdier i datasettet. N친r manglende verdier ble oppdaget, tok vi i bruk Pandas-funksjonen fillna(), som erstatter NaN-verdier med spesifiserte verdier. I de fleste tilfeller brukte vi median som erstatning, men i behandlingen av historiske data testet vi ogs친 med gjennomsnitt og null som alternativer. Det er viktig 친 v칝re klar over at slike metoder kan introdusere un칮yaktigheter. V칝rdata varierer betydelig fra dag til dag, og det er derfor vanskelig 친 erstatte manglende verdier uten 친 risikere 친 forvrenge virkeligheten. Spesielt i tilfeller med ekstreme verdier i datasettet kan gjennomsnitt v칝re en d친rlig erstatning, ettersom det er sv칝rt sensitivt for slike avvik. I slike situasjoner kan median v칝re et bedre valg, da den er mer robust mot ekstreme verdier og gir et mer representativt bilde av datasettet.


2) Vi har brukt list comprehentions for 친 hente ut og analysere temperaturdata (datasettet vi fokuserer mest p친) i b친de fremtidig og historisk analyse. Historisk sett brukte vi det hovedsakelig for 친 hente ut og filtrere dataen tidlig i koden. Fremtidig sett brukte vi det veldig lignende, men uttrykket p친 en nogenlunde annerledes metode. Et sterkt punkt for list comprehentions er 친 hente ut og analysere data, noe vi fikk sterk nytte av. 

3) I forhold til vanlig Pandas tillater Pandas SQL h친ndtering med mer SQL orientert spr친k. Pandas SQL tillater ogs친 mer fleksibelitet og alternativer ved datah친ndteringen, i tilloegg til at koden blir mer intuitiv 친 skrive. Kodens leslighet gjelder spesielt n친r en 칮nsker 친 jobbe inn flere kriterier samtidig. For eksempel blir det at vi henter ut middelvind over 5 i verdi gjort mer leslig og oversiktelig enn i vanlig pandas. 

4) De to hovedproblemene datasett pleier 친 inkludere er manglende verdier, og uteliggende verdier. Slik var situasjonen for v친re datasett ogs친. Vi har i begge datasettene filtrert for manglende verdier via den tidligere nevnte fillna. I historisk databehandling har vi ogs친 filtrert for ekstremverider, via funksjonen ekstremVerdier. Da den fremtidige dataen er skapt gjennom en vnasklig mattematisk prediktiv modell anser vi at om noen ekstremverdier har sluppet gjennom prosessen og utgjevningen meterologisk institutt har tatt i bruk er de nok verdt 친 beholde. Vi har ogs친 lagt inn automatisk rettende kode for formateringsfeil.

5) Om Funksjonene:
- Funksjonen datafiltrering leser inn v칝rdata fra en CSV-fil, konverterer tidskolonnen til riktig datoformat, s칮rger for at numeriske kolonner har riktig datatype (float), og fyller inn eventuelle manglende verdier med kolonnegjennomsnittet. Dette sikrer at datasettet er strukturert og klart for videre analyse.
- Funksjonen ekstremVerdier fjerner unormale eller ekstreme verdier i datasettet ved 친 filtrere temperaturer utenfor omr친det -50 til 50 grader Celsius og vindhastigheter utenfor omr친det 0 til 115 m/s. Dette bidrar til 친 sikre at dataene er realistiske og p친litelige for videre analyse.
- Funksjonen manglendeData h친ndterer manglende verdier i datasettet ved 친 bruke forskjellige metoder, avhengig av hva som er valgt:
    - "mean": Fyller inn manglende verdier med gjennomsnittet for den aktuelle kolonnen.
    - "median": Fyller inn med medianverdien for kolonnen.
    - "zero": Fyller inn med 0 for manglende verdier.





#
### Innhold i prosjekt
- [Informasjon om mapper](/README.md)
- [Mappe 1](/src/Mappe%201/README.md)
- [Mappe 2](/src/Mappe%202/README.md)




 
