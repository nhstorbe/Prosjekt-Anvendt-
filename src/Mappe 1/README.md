
# üåç Milj√∏dataanalyseapplikasjon

Dette prosjektet analyserer v√¶rdata fra datakilden Yr, ved hjelp av meteorologiske API-er. Programmet henter, prosesserer og analyserer v√¶rinformasjon i Stryn ved hjelp av Python.


![bilde](resources/IMG_7762.JPG)


## Innhold

- [Oppgave 1: Sett opp utviklingsmilj√∏](#Oppgave1)
- [Oppgave 2: Datainnsamling](#Oppgave2)
- [Oppgave 3: Databehandling](#Oppgave3)

---

## üõ†Ô∏è Oppgave 1 Utviklings milj√∏ 

Sp√∏rsm√•l for √∏vingstime:
- Hvordan fungerer er PEP 8?
- Hva er det som √∏nskes √• oppn√• ut ifra oppgave 2?
- Samme sp√∏rsm√•l for oppgave 3?
- Hvordan vil en vise at vi har tatt i bruk list comprehensions, iterators og pandassqlfd?
- Hvordan skal vi utforske og forst√• dataens struktur og innhold?
- Hva for noe svar √∏nskes det?
- Skal sp√∏rsm√•lene nederst p√• hver oppgavetekst besvares i relevant kodefil, samlet pdf, eller i det hele tatt? 
- N√•r f√•r vi tilbakemelding p√• mappe 1? Med tanke p√• oppf√∏lgningsfeil 

hente dataen 
filtrere dataen, pandas null 
s√∏ke opp hvordan filtrere store mengder v√¶r data pandas.null 
gj√∏re det generelt mer clean 
gj√∏re det mer finere 



[Test at utviklingsmilj√∏et fungerer](src/utviklingsmilj√∏.ipynb)

## ‚úâÔ∏è Datainnsamling og databehandling av historisk v√¶rdata

[CSV fil med v√¶rdata i Stryn fra 1 Mars 2024 til 1 Mars 2025](data/table.csv)
- I tillegg til en csv fil som tar for seg historisk data har vi ogs√• tatt i bruk en API fra Meteoroliske institutt der vi samler inn sanntidsdata hver time for de neste 10 dagene. 

Gjennom internett kan en finne en stor mengde brukbare kilder p√• relevant data til dette prosjektet. Av den grunn trenger en √• spisse seg inn mot den mest relevante. Det viktigste kriteriet i relasjon til kildevalg for oss er kildeautoritet. Av den grunn s√• vi f√∏rst p√• offentlige, og statlige kilder. Vi s√• av den grunn p√• [yr](https://www.yr.no), [NOAA](https://www.ncei.noaa.gov/cdo-web/datasets) og [Meterologiask institutt](https://www.met.no/en/free-meteorological-data). Vi valgte i f√∏rste omgang disse nettstedene da de enten er internasjonalt annerkjente organisasjoner, eller statlige meterologiske institusjoner. Vi f√∏lte av den grunn at alle tre var p√•litelige kilder med god autoritet og datatilgang. Da dataene fra sidene enten er hentet fra eller brukes til aktiv forskning har vi ogs√• god tiltro til kvaliteten p√• dataen. Vi valgte √• bruke meterologisk institutt for fremtidsrettet dataanalyse grunnet at de tok i bruk .json format, og at √• f√• tak i dataen fra deres nettside var lettest. For historisk ananlyse, hvor vi ikke trengte √• holde dataen oppdatert, men heller √∏nsekt en st√∏rre mengde tilgjengelig, valgte vi √• ta i bruk .csv fra yr. Hvorfor utdyper vi under. 

Vi vlagte .json format for analyse av fremtidig data av flere grunner. De grunnleggende formene en ofte tar i bruk for prosjekter av denne typen virket √• v√¶re .csv, .json og .xml. Vi har ikke mye kunnskap til .xml, og formatet har en mulig kompleksitet som g√•r langt forbi v√•re krav, p√• god bekostning av filst√∏rrelse. .csv(comma seperated values)-filer er den simpleste typen data-fil som er vanlig √• ta i bruk. En .csv-fil inneholder linjer med data separert med "," og er derfor sv√¶rt leselige for mennesker, og veldig lett √• sette inn i excel-filer. .json(Javascript Object Notation)-filer er tekstbaserte, simple og effektive. .json er ikke like effektive st√∏rrelsesmessig som .csv, men er ganske n√¶rt..json er bygd opp av arrays og objekter. En ser ofte objekt etter objekt som inneholder lik data om tilsvarende situasjon over tid, f.eks 

{
    "temp": "30*C",
    "wind": "5m/s",
    "wind.direction": "NE"
}

.json er ogs√• ganske leselig for mennesker, og relativt lett √• h√•ndtere datamessig. Formatet er ogs√• flexibelt og bredt kompatibelt med forskjellige formler. Vi valgte .json fordi det ga √∏kt flexibilitet og kompatibilitet i forhold til .csv, med minimal √∏kninig i filst√∏rrelse og leselighet. .json var ogs√• lettere √• st√∏tte med API-er for √• holde dataen konstant oppdatert, noe vi m√• for √• holde dataen konstant fremtidsrettet. Vi har brukt en API st√∏ttet .json fil nettopp fordi vi da alltid vil ha filen automatisk oppdatert. 

For den historiske dataen ga det mening √• ta i bruk en .csv fil fordi den er mindre i st√∏rrelse per datapunkt enn en .json, og vi ikke trengte en den API-integrert. .csv filer kan API-integreres, men de fleste bruker for tiden .json for proseser og API-er p√• nett, noe som hadde gjort dette vanskligere √• finne. 

Vi har brukt en API som henter ned en .json p√• spesifiserte lengde- og breddegrader fra meterologisk institutt sin nettside. Den tillater oss √• kj√∏re programmet med oppdatert forecasts data hver gang programmet kj√∏res. Vi henter ned tidspunkt, temperatur, regnmengde og vindhastighet. Siden vi har de samme datapunktene i v√•r historiske data kan vi bruke alle for analyser. Siden vi har tilsvarende historisk data kan vi gjennomf√∏re analyser for √• b√•de se om vi sier oss enige med v√•re analytiske verkt√∏y, men ogs√• for √• kunne bruke historisk data for √• hjelpe √• erstatte manglende data i .json datasettet. 

## ü§ñ Datainnsamling og databehandling av fremtidig v√¶rdata

Vi har brukt flere forskjellige metoder for √• h√•ndtere manglende verdier i verdissettet. Ettersom vi har forventet noe manglende data er dette noe vi har sk√•net oss mot i st√∏rre grad. B√•de den historiske og fremtidige dataen blir behandlet med fillna for √• identifisere og erstatte manglende data. I begge filene bruker vi gjennomsnittet for √• erstatte den manglende verdien, men i den historiske dataen har vi ogs√• satt opp mulighet for √• erstatte den med 0 eller medianen. Den historiske dataen er blitt gitt flere muligheter, da datasettet for √• skape disse er st√∏rre. Grunnen til det er at om en tar gjennomsnittsdataen, selv fra samme tidspunkt andre dager, bliir det vanskelig √• gjenskape rimelig data. V√¶ret endrer seg mye fra dag til dag, noe som gj√∏r det vanskelig. I fremtiden kunne vi eventuelt sett p√• √• lage analysere for √• finne en rimelig graf for temperaturendring p√• tvers av et d√∏gn, for s√• √• sette den over de n√¶rmeste datapunktene. Vi kunne ogs√• sett p√• historisk v√¶rdata for samme tidsperiode i tidligere √•r. Derimot hadde det blitt komplekst, og vi amngler den relevante datamengden, s√• metodene vi for n√• har tatt i bruk er gode nok for en tiln√¶ring. 

Vi har brukt list comprehentions for √• hente ut og analysere temperaturdata (datasettet vi fokuserer mest p√•) i b√•de fremtidig og historisk analyse. Historisk sett brukte vi det hovedsakelig for √• hente ut og filtrere dataen tidlig i koden. Fremtidig sett brukte vi det veldig lignende, men uttrykket p√• en nogenlunde annerledes metode. Et sterkt punkt for list comprehentions er √• hente ut og analysere data, noe vi fro sterk nytte av. 

I forhold til vanlig Pandas tillater Pandas SQL h√•ndtering med mer SQL orientert spr√•k. Pandas SQL tillater ogs√• mer fleksibelitet og alternativer ved datah√•ndteringen, i tilloegg til at koden blir mer intuitiv √• skrive. Kodens leslighet gjelder spesielt n√•r en √∏nsker √• jobbe inn flere kriterier samtidig. For eksempel blir det at vi henter ut middelvind over 5 i verdi gjort mer leslig og oversiktelig enn i vanlig pandas. 

De to hovedproblemene datasett pleier √• inkludere er manglende verdier, og uteliggende verdier. Slik var situasjonen for v√•re datasett ogs√•. Vi har i begge datasettene filtrert for manglende verdier via den tidligere nevnte fillna. I historisk databehandling har vi ogs√• filtrert for ekstremverider, via funksjonen ekstremVerdier. Da den fremtidige dataen er skapt gjennom en vnasklig mattematisk prediktiv modell anser vi at om noen ekstremverdier har sluppet gjennom prosessen og utgjevningen meterologisk institutt har tatt i bruk er de nok verdt √• beholde. Vi har ogs√• lagt inn automatisk rettende kode for formateringsfeil. 
