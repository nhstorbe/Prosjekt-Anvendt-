
# 游깴 Mappe 1: Datainnsamling og forberedelse
I den f칮rste mappen i prosjektet var form친let 친 sette opp et utviklingsmilj칮, samle inn data og behandle og analysere den. 

Gruppen bestemt seg for 친 dele alle oppgavene i to deler, da alle oppgavene blir gjort to ganger med to ulike datasett. Det p친  der b친de historisk data og fremtidsrettet data blir analysert, da dette var tilgjengelig p친 Yr sine nettsider. Oppgavene blir beskrevet og gjennomf칮rt i hver sin respektive fil. 


#
### Innhold i mappen
- [Testing av utviklingsmilj칮](../Mappe%201/utviklingsmilj칮.ipynb)
- [Databehandling av historisk data](../Mappe%201/data_behandling_fremtid.ipynb)
- [Databehandling av fremtidsrettet data](../Mappe%201/data_behandling_fremtid.ipynb)

#
### 九괦잺 Datainnsamling og databehandling av historisk v칝rdata

- [CSV fil med v칝rdata i Stryn fra 1 Mars 2024 til 1 Mars 2025](data/table.csv)
- [Datainnsamling og databehandling av historisk v칝rdata](src/data_behandling_historisk.ipynb)
- I tillegg til en csv fil som tar for seg historisk data har vi ogs친 tatt i bruk en API fra Meteoroliske institutt der vi samler inn sanntidsdata hver time for de neste 10 dagene. 

Gjennom internett kan en finne en stor mengde brukbare kilder p친 relevant data til dette prosjektet. Av den grunn trenger en 친 spisse seg inn mot den mest relevante. Det viktigste kriteriet i relasjon til kildevalg for oss er kildeautoritet. Av den grunn s친 vi f칮rst p친 offentlige, og statlige kilder. Vi s친 av den grunn p친 [yr](https://www.yr.no), [NOAA](https://www.ncei.noaa.gov/cdo-web/datasets) og [Meterologiask institutt](https://www.met.no/en/free-meteorological-data). Vi valgte i f칮rste omgang disse nettstedene da de enten er internasjonalt annerkjente organisasjoner, eller statlige meterologiske institusjoner. Vi f칮lte av den grunn at alle tre var p친litelige kilder med god autoritet og datatilgang. Da dataene fra sidene enten er hentet fra eller brukes til aktiv forskning har vi ogs친 god tiltro til kvaliteten p친 dataen. Vi valgte 친 bruke meterologisk institutt for fremtidsrettet dataanalyse grunnet at de tok i bruk .json format, og at 친 f친 tak i dataen fra deres nettside var lettest. For historisk ananlyse, hvor vi ikke trengte 친 holde dataen oppdatert, men heller 칮nsekt en st칮rre mengde tilgjengelig, valgte vi 친 ta i bruk .csv fra yr. Hvorfor utdyper vi under. 

Vi vlagte .json format for analyse av fremtidig data av flere grunner. De grunnleggende formene en ofte tar i bruk for prosjekter av denne typen virket 친 v칝re .csv, .json og .xml. Vi har ikke mye kunnskap til .xml, og formatet har en mulig kompleksitet som g친r langt forbi v친re krav, p친 god bekostning av filst칮rrelse. .csv(comma seperated values)-filer er den simpleste typen data-fil som er vanlig 친 ta i bruk. En .csv-fil inneholder linjer med data separert med "," og er derfor sv칝rt leselige for mennesker, og veldig lett 친 sette inn i excel-filer. .json(Javascript Object Notation)-filer er tekstbaserte, simple og effektive. .json er ikke like effektive st칮rrelsesmessig som .csv, men er ganske n칝rt..json er bygd opp av arrays og objekter. En ser ofte objekt etter objekt som inneholder lik data om tilsvarende situasjon over tid, f.eks 

{
    "temp": "30*C",
    "wind": "5m/s",
    "wind.direction": "NE"
}

.json er ogs친 ganske leselig for mennesker, og relativt lett 친 h친ndtere datamessig. Formatet er ogs친 flexibelt og bredt kompatibelt med forskjellige formler. Vi valgte .json fordi det ga 칮kt flexibilitet og kompatibilitet i forhold til .csv, med minimal 칮kninig i filst칮rrelse og leselighet. .json var ogs친 lettere 친 st칮tte med API-er for 친 holde dataen konstant oppdatert, noe vi m친 for 친 holde dataen konstant fremtidsrettet. Vi har brukt en API st칮ttet .json fil nettopp fordi vi da alltid vil ha filen automatisk oppdatert. 

For den historiske dataen ga det mening 친 ta i bruk en .csv fil fordi den er mindre i st칮rrelse per datapunkt enn en .json, og vi ikke trengte en den API-integrert. .csv filer kan API-integreres, men de fleste bruker for tiden .json for proseser og API-er p친 nett, noe som hadde gjort dette vanskligere 친 finne. 

Vi har brukt en API som henter ned en .json p친 spesifiserte lengde- og breddegrader fra meterologisk institutt sin nettside. Den tillater oss 친 kj칮re programmet med oppdatert forecasts data hver gang programmet kj칮res. Vi henter ned tidspunkt, temperatur, regnmengde og vindhastighet. Siden vi har de samme datapunktene i v친r historiske data kan vi bruke alle for analyser. Siden vi har tilsvarende historisk data kan vi gjennomf칮re analyser for 친 b친de se om vi sier oss enige med v친re analytiske verkt칮y, men ogs친 for 친 kunne bruke historisk data for 친 hjelpe 친 erstatte manglende data i .json datasettet. 

## 游뱄 Datainnsamling og databehandling av fremtidig v칝rdata

[Datainnsamling og databehandling av fremtidig v칝rdata](src/data_behandling_fremtid.ipynb)

Vi har brukt flere forskjellige metoder for 친 h친ndtere manglende verdier i verdissettet. Ettersom vi har forventet noe manglende data er dette noe vi har sk친net oss mot i st칮rre grad. B친de den historiske og fremtidige dataen blir behandlet med fillna for 친 identifisere og erstatte manglende data. I begge filene bruker vi gjennomsnittet for 친 erstatte den manglende verdien, men i den historiske dataen har vi ogs친 satt opp mulighet for 친 erstatte den med 0 eller medianen. Den historiske dataen er blitt gitt flere muligheter, da datasettet for 친 skape disse er st칮rre. Grunnen til det er at om en tar gjennomsnittsdataen, selv fra samme tidspunkt andre dager, bliir det vanskelig 친 gjenskape rimelig data. V칝ret endrer seg mye fra dag til dag, noe som gj칮r det vanskelig. I fremtiden kunne vi eventuelt sett p친 친 lage analysere for 친 finne en rimelig graf for temperaturendring p친 tvers av et d칮gn, for s친 친 sette den over de n칝rmeste datapunktene. Vi kunne ogs친 sett p친 historisk v칝rdata for samme tidsperiode i tidligere 친r. Derimot hadde det blitt komplekst, og vi amngler den relevante datamengden, s친 metodene vi for n친 har tatt i bruk er gode nok for en tiln칝ring. 

Vi har brukt list comprehentions for 친 hente ut og analysere temperaturdata (datasettet vi fokuserer mest p친) i b친de fremtidig og historisk analyse. Historisk sett brukte vi det hovedsakelig for 친 hente ut og filtrere dataen tidlig i koden. Fremtidig sett brukte vi det veldig lignende, men uttrykket p친 en nogenlunde annerledes metode. Et sterkt punkt for list comprehentions er 친 hente ut og analysere data, noe vi fro sterk nytte av. 

I forhold til vanlig Pandas tillater Pandas SQL h친ndtering med mer SQL orientert spr친k. Pandas SQL tillater ogs친 mer fleksibelitet og alternativer ved datah친ndteringen, i tilloegg til at koden blir mer intuitiv 친 skrive. Kodens leslighet gjelder spesielt n친r en 칮nsker 친 jobbe inn flere kriterier samtidig. For eksempel blir det at vi henter ut middelvind over 5 i verdi gjort mer leslig og oversiktelig enn i vanlig pandas. 

De to hovedproblemene datasett pleier 친 inkludere er manglende verdier, og uteliggende verdier. Slik var situasjonen for v친re datasett ogs친. Vi har i begge datasettene filtrert for manglende verdier via den tidligere nevnte fillna. I historisk databehandling har vi ogs친 filtrert for ekstremverider, via funksjonen ekstremVerdier. Da den fremtidige dataen er skapt gjennom en vnasklig mattematisk prediktiv modell anser vi at om noen ekstremverdier har sluppet gjennom prosessen og utgjevningen meterologisk institutt har tatt i bruk er de nok verdt 친 beholde. Vi har ogs친 lagt inn automatisk rettende kode for formateringsfeil. 
